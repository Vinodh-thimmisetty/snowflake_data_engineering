-- ENABLE AI 
use role accountadmin;
ALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'AWS_US';
SHOW PARAMETERS LIKE 'CORTEX_ENABLED_CROSS_REGION' IN ACCOUNT;


use role sysadmin;

use schema aqi_dev_db.staging;
use warehouse ADHOC_WH;
ALTER WAREHOUSE ADHOC_WH RESUME;

CREATE OR REPLACE STAGE AQI_DEV_DB.STAGING.JSON_INTERNAL_STAGE
  DIRECTORY = (
    ENABLE = TRUE
    AUTO_REFRESH = TRUE
  )
  FILE_FORMAT = (
    TYPE = JSON
    STRIP_OUTER_ARRAY = TRUE
    IGNORE_UTF8_ERRORS = TRUE
    COMPRESSION = AUTO
  )
  COPY_OPTIONS = (
    ON_ERROR = 'CONTINUE'
    PURGE = TRUE
    FORCE = FALSE
    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE
    ENFORCE_LENGTH = TRUE
  )
  COMMENT = 'Internal stage for JSON data ingestion. This stage enables automated directory monitoring and handles JSON files with UTF-8 encoding. Perfect for streaming analytics and real-time data processing workflows.';

CREATE OR REPLACE FILE FORMAT AQI_DEV_DB.STAGING.JSON_FILE_FORMAT
    TYPE = 'JSON'
    COMPRESSION = 'AUTO'
    ENABLE_OCTAL = FALSE
    ALLOW_DUPLICATE = FALSE
    STRIP_OUTER_ARRAY = TRUE
    STRIP_NULL_VALUES = TRUE
    IGNORE_UTF8_ERRORS = FALSE
    SKIP_BYTE_ORDER_MARK = TRUE
    DATE_FORMAT = 'AUTO'
    TIME_FORMAT = 'AUTO'
    TIMESTAMP_FORMAT = 'AUTO'
    BINARY_FORMAT = 'HEX'
    TRIM_SPACE = TRUE
    REPLACE_INVALID_CHARACTERS = TRUE
    COMMENT = 'Standard JSON file format with default configurations for data loading';

SHOW STAGES;
 
LIST @JSON_INTERNAL_STAGE;

CREATE OR REPLACE TRANSIENT TABLE AQI_DEV_DB.STAGING.RAW_AQI_DATA (
    ID NUMBER AUTOINCREMENT START 1 INCREMENT 1 PRIMARY KEY,
    INDEX_RECORD_TS TIMESTAMP NOT NULL,
    JSON_DATA VARIANT NOT NULL,
    JSON_DATA_RECORDS NUMBER DEFAULT 0,
    JSON_VERSION TEXT NOT NULL,
    _STG_FILE_NAME TEXT,
    _STG_FILE_LOAD_TS TIMESTAMP,
    _STG_FILE_MD5 TEXT,
    _COPY_DATA_TS TIMESTAMP DEFAULT CURRENT_TIMESTAMP()
);


CREATE OR REPLACE TASK AQI_DEV_DB.STAGING.LOAD_INDIA_AQI_DATA
    WAREHOUSE = LOAD_WH -- remove this for SERVERLESS option
    SCHEDULE = 'USING CRON 0 0 20 * * Asia/Kolkata'
    SUSPEND_TASK_AFTER_NUM_FAILURES = 1
    TASK_AUTO_RETRY_ATTEMPTS = 0 
    COMMENT = "Task to move data from Stage Location to Table periodically"
    ALLOW_OVERLAPPING_EXECUTION = FALSE
    TIMESTAMP_INPUT_FORMAT = 'AUTO',
    TIMESTAMP_OUTPUT_FORMAT = 'YYYY-MM-DD HH24:MI:SS.FF',
    TIMEZONE = 'Asia/Kolkata'
    CONFIG=$${"env": "non-prod", "owned_by": "vinodh" }$$
AS 
COPY INTO AQI_DEV_DB.STAGING.RAW_AQI_DATA
(
    INDEX_RECORD_TS,
    JSON_DATA,
    JSON_DATA_RECORDS,
    JSON_VERSION,
    _STG_FILE_NAME,
    _STG_FILE_LOAD_TS,
    _STG_FILE_MD5)
FROM (
    SELECT 
        TRY_TO_TIMESTAMP($1:records[0].last_update::TEXT, 'DD-MM-YYYY HH24:MI:SS')  AS INDEX_RECORD_TS,
        $1::VARIANT AS JSON_DATA,
        $1:total::NUMBER AS JSON_DATA_RECORDS,
        $1:version::TEXT AS JSON_VERSION,
        METADATA$FILENAME AS _STG_FILE_NAME,
        METADATA$FILE_LAST_MODIFIED AS _STG_FILE_LOAD_TS,
        METADATA$FILE_CONTENT_KEY AS _STG_FILE_MD5
    FROM @AQI_DEV_DB.STAGING.JSON_INTERNAL_STAGE 
    -- (FILE_FORMAT => 'AQI_DEV_DB.STAGING.JSON_FILE_FORMAT')
)
FILE_FORMAT = (FORMAT_NAME = 'AQI_DEV_DB.STAGING.JSON_FILE_FORMAT', type = JSON)
ON_ERROR = ABORT_STATEMENT
MATCH_BY_COLUMN_NAME = NONE -- !Important 
PURGE = FALSE -- !Important Will be removed from the Stage 
FORCE = FALSE
;

-- LATERAL FLATTEN(input => JIS.$1:records) R;
 

SHOW TASKS IN SCHEMA STAGING;

USE ROLE ACCOUNTADMIN;
GRANT EXECUTE TASK, EXECUTE MANAGED TASK ON ACCOUNT TO ROLE SYSADMIN;

USE ROLE SYSADMIN;
ALTER TASK AQI_DEV_DB.STAGING.LOAD_INDIA_AQI_DATA SUSPEND;
ALTER TASK AQI_DEV_DB.STAGING.LOAD_INDIA_AQI_DATA RESUME; 

-- DROP TASK LOAD_INDIA_AQI_DATA;

select * exclude(json_data),
row_number() over (partition by index_record_ts order by _stg_file_load_ts desc) as latest_file_rank 
from 
AQI_DEV_DB.STAGING.RAW_AQI_DATA;


SELECT * FROM SNOWFLAKE.ACCOUNT_USAGE.TASK_VERSIONS WHERE DATABASE_NAME='AQI_DEV_DB' AND SCHEMA_NAME='STAGING' AND "NAME" = 'LOAD_AQI_DATA_TASK';

SELECT * FROM SNOWFLAKE.ACCOUNT_USAGE.TASK_HISTORY WHERE DATABASE_NAME='AQI_DEV_DB' AND SCHEMA_NAME='STAGING' AND "NAME" = 'LOAD_AQI_DATA_TASK';

SELECT *
  FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME => 'LOAD_AQI_DATA_TASK', RESULT_LIMIT => 10, ERROR_ONLY => FALSE))
  ORDER BY SCHEDULED_TIME;

SELECT *
  FROM TABLE(INFORMATION_SCHEMA.CURRENT_TASK_GRAPHS(ROOT_TASK_NAME => 'LOAD_AQI_DATA_TASK'))
  ORDER BY SCHEDULED_TIME;

SELECT * FROM SNOWFLAKE.ACCOUNT_USAGE.COPY_HISTORY WHERE TABLE_CATALOG_NAME='AQI_DEV_DB' AND TABLE_SCHEMA_NAME='STAGING' AND TABLE_NAME='RAW_AQI_DATA';

-- check if files are copied to stage or not
SELECT METADATA$FILENAME AS FILE_NAME
FROM @identifier($stage_name)
EXCEPT
SELECT DISTINCT FILE_NAME
FROM SNOWFLAKE.ACCOUNT_USAGE.COPY_HISTORY
WHERE TABLE_CATALOG_NAME = $catalog_name 
AND TABLE_SCHEMA_NAME = $schema_name 
AND TABLE_NAME = $table_name 
AND STATUS = 'Loaded'